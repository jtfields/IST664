{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GPT2Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXz2iu4u7_Y9"
      },
      "source": [
        "#GPT2 Demo\n",
        "#Source: https://medium.com/swlh/how-to-use-gpt-2-in-google-colab-de44f59199c1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5LoFQdEElcV",
        "outputId": "0581d523-98f5-4f8b-a3d3-7353de95ddcd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC_rKnKzFn-T",
        "outputId": "2b185fab-873b-4bf0-c4c3-305f29e5fa93"
      },
      "source": [
        "# ONLY RUN ONCE\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!mkdir gpt-2\n",
        "%cd gpt-2/\n",
        "!git clone https://github.com/openai/gpt-2.git\n",
        "%cd cd gpt-2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "mkdir: cannot create directory ‘gpt-2’: File exists\n",
            "/content/drive/My Drive/gpt-2\n",
            "fatal: destination path 'gpt-2' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: 'cd gpt-2'\n",
            "/content/drive/My Drive/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_9-EgktFs7a",
        "outputId": "ac6cb03e-a9e2-461f-ecea-e233668581d1"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/gpt-2/gpt-2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qeNBEUJFxvw",
        "outputId": "ae0e854f-afcb-4584-899b-acb133c611a3"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "B576YzRGF2nP",
        "outputId": "351cb65b-78a5-4fef-e109-dc584ad7278c"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/07/a119a1aa04d37bc819940d95ed7e135a7dcca1c098123a3764a6dcace9e7/fire-0.4.0.tar.gz (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.5MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 18.6MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.5MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.12.5)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=a61c29826353d8c288e3d638576d3424a7df4da0c78a8e92ba32648d39a79705\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/19/30/1ea0cad502dcb4e66ed5a690279628c827aea38bbbab75d5ed\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-linux_x86_64.whl size=534380 sha256=e3c41cad2a2e81514abd86bd06dcd447fb996372465dbfc7ad06309ea43df94c\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex, idna, requests, tqdm\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed fire-0.4.0 idna-2.8 regex-2017.4.5 requests-2.21.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neXwzoUuF8je",
        "outputId": "d797656d-53e4-496e-bf59-ba4422e6a7f7"
      },
      "source": [
        "!python3 download_model.py 124M\n",
        "!python3 download_model.py 355M\n",
        "!python3 download_model.py 774M\n",
        "!python3 download_model.py 1558M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 951kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 1.69Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 877kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [03:30, 2.37Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 5.05Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 920kit/s]                                                  \n",
            "Fetching vocab.bpe: 457kit [00:00, 866kit/s]                                                        \n",
            "Fetching checkpoint: 1.00kit [00:00, 986kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 1.77Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 981kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [01:48, 13.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 7.72Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 1.49Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 864kit/s]                                                        \n",
            "Fetching checkpoint: 1.00kit [00:00, 927kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 1.62Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 904kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001:  40%|██████▎         | 1.23G/3.10G [10:06<15:23, 2.02Mit/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 444, in read\n",
            "    data = self._fp.read(amt)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 461, in read\n",
            "    n = self.readinto(b)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 505, in readinto\n",
            "    n = self.fp.readinto(b)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 929, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"download_model.py\", line 26, in <module>\n",
            "    for chunk in r.iter_content(chunk_size=chunk_size):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/models.py\", line 750, in generate\n",
            "    for chunk in self.raw.stream(chunk_size, decode_content=True):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 496, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/response.py\", line 461, in read\n",
            "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 116, in __exit__\n",
            "    def __exit__(self, type, value, traceback):\n",
            "KeyboardInterrupt\n",
            "Fetching checkpoint: 1.00kit [00:00, 919kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 1.68Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 941kit/s]                                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yHnEm4Sg0Tu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSLENZpyGD9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22960e9-131e-494d-e2d8-77af10e48e20"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-06-01 16:58:15.264664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-01 16:58:15.319685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:15.320330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-01 16:58:15.350976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-01 16:58:15.514657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-01 16:58:15.665286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-01 16:58:15.685646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-01 16:58:15.870481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-01 16:58:15.888130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-01 16:58:16.287476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-01 16:58:16.287715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.288501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.289129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-01 16:58:16.305469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-06-01 16:58:16.305877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f485e3640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-01 16:58:16.305916: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-06-01 16:58:16.575308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.576248: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562f485e3b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-06-01 16:58:16.576278: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-06-01 16:58:16.576499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.577071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-01 16:58:16.577169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-01 16:58:16.577199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-06-01 16:58:16.577214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-06-01 16:58:16.577228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-06-01 16:58:16.577244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-06-01 16:58:16.577258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-06-01 16:58:16.577271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-01 16:58:16.577333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.577934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.578465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-06-01 16:58:16.582267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-06-01 16:58:16.583940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-01 16:58:16.583975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-06-01 16:58:16.583996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-06-01 16:58:16.587088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.587936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 16:58:16.588558: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-01 16:58:16.588691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt-2/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Model prompt >>> What is NLP?\n",
            "2021-06-01 16:58:49.043437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "NLP is a collection of ideas, ideas which have been incorporated into popular culture and are popular in social media today. It consists of a number of sub-sections which are differentiates between the NLP and a more traditional version. The most commonly used sub-section is \"the history of ideas.\"\n",
            "\n",
            "NLP starts off in the form of discussions on topics such as \"Why does technology matter?\" \"Is there an afterlife?\", \"What is a good or evil?\" and \"Can we all live without it?\"\n",
            "\n",
            "One of the most common views of NLP is that those who are pessimistic about technological progress should stay in the present so that the experience of the future can be shared around the globe. This kind of attitude is generally found among those who are pessimistic about technology.\n",
            "\n",
            "On the other hand, those who advocate technology-based solutions to social problems will tend to advocate for the future in other ways. In order for a society to be sustainable without technological advancements, it must work in a way that benefits all people.\n",
            "\n",
            "Examples of different subsecutions\n",
            "\n",
            "NLP groups are created every week based on ideas expressed in the comments of others. The most common sub-sub-section within a group are that of the NLP or that of the group that seeks to \"do something.\" A lot of these groups, as described herein, share in common a belief about the need to have \"something\" with society. The majority of those groups are found within groups such as the NLP-a and the NLP-aA, as discussed above.\n",
            "\n",
            "For example, some groups like the NLP-A have a more specific idea in mind than the group of people who like to \"do things in the present.\" However, most of it is considered \"good\" by the community.\n",
            "\n",
            "In the context of technological advancement, it is well established that technology has already greatly improved a person's ability to express and feel the potentialities of the present. Therefore, such \"things\" have a profound impact on social and personal well-being. A lot of people believe that technological change is a cause for good health and that only those with health conditions should have an incentive to act through technology.\n",
            "\n",
            "The same is true of many other different sub-subtractions within the group, which tend to emphasize a higher moral standards associated with social progress and that seek to make society less \"dangerous\" or \"more \"efficient.\"\n",
            "\n",
            "Also, some sub-subtractions also\n",
            "================================================================================\n",
            "Model prompt >>> What is natural language processing?\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "The most common way in which a computer learns is to apply a language to a set of input tasks, usually a series of strings that are part of a language. In language processing, these programs are then translated and processed as if they had written that same string. In practice, these languages are much more complex than the languages most likely to be used in the game. This raises the question whether the way we learn languages is necessarily the only way for computers to learn anything like what we learn in computer games or other complex data structures.\n",
            "\n",
            "\n",
            "What are the similarities and differences between human and machine language processing (HLS)?\n",
            "\n",
            "Humans use \"machine\" for many purposes. They are usually trained algorithms such as reinforcement learning (SR) and reinforcement learning in machine learning. Human HLS programs have a similar learning rate to any AI programs but are more capable of recognizing and processing data more efficiently.\n",
            "\n",
            "On the other hand, HLS programs that have specific human features (eg, a language grammar) often have fewer human features. This is to be expected in HLS programs that do have certain behaviors like looking at the computer screen and responding to what it sees as inputs. HLS programs that are more complex are not more capable of recognizing more data in the background or the current state of the screen.\n",
            "\n",
            "To understand how HLS programs are structured it's worth considering the human input model. HLS programs typically consist of \"input\" systems or tasks such as generating and performing a certain sort of task (often a specific word, such as a character, or object, for example). In many HLS programs, the human input model is the first input for each task, then for each element that can be displayed as the string to be generated (e.g., using the keyboard) and processed by the HLS program. This means that a system such as a human HLS program can learn an input and then, after processing the output, choose which value should be displayed in the output. This, in turn, determines the value displayed in the final output.\n",
            "\n",
            "In order to have accurate representations of the value that a system should display in a human input system, HLS programs have a number of parameters that they must control. Each of these parameters may be set to a certain value and may or may not allow the HLS program to use certain input data. It's important to note that this does not necessarily mean that HLS programs should not display human input data such as pictures, music, or speech\n",
            "================================================================================\n",
            "Model prompt >>> Who is Dr. Praveen Madaraju?\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "The first question is: How many do you know?\n",
            "\n",
            "And he is known in the world as \"Praveen Madaraju\". He is described as being a former Indian officer but has also been an Indian diplomat and a diplomat in the United States. He is known primarily as the ex-director of the Centre for Foreign Policy Studies and as the founder of Bhutan, the world's largest state.\n",
            "\n",
            "But what do you know about this man-child of a man in his seventies? He didn't get into politics or academia but he was an expert on the \"Tindaramika\" or the idea that women who live up to their potential have all the rights and privileges of men as they should.\n",
            "\n",
            "There is a lot of controversy over the nature of Madaraju's work and not just on television programmes and in public places.\n",
            "\n",
            "The Madaraju project, in itself, has been labelled by former government and human rights activists as the \"one-sided project of an ex-minister\".\n",
            "\n",
            "The Madaraju project, in itself, has been labelled by former government and human rights activists as the \"one-sided project of an ex-minister\".\n",
            "\n",
            "Madaraju's father, a civil servant, came to India with a child he thought would grow up into a man.\n",
            "\n",
            "He had come along and been living with his wife in an unknown place.\n",
            "\n",
            "The three young children were very well-fed and had all a free will. This took them to visit one of Madaraju's daughters when their parents visited and they had been told Madaraju's father was in a long-term relationship and would marry her soon. He became a man.\n",
            "\n",
            "Mudra, when Madaraju went to college, came along. He liked how women looked; they had all a lot of rights and privileges. They gave him a job. They gave him a house. All of a sudden that was that thing.\n",
            "\n",
            "He came back and he said that he wanted to live in Delhi, but he wanted to go in Mumbai. He said 'No way to live in Mumbai!', which was a very odd way to talk about a man who had come to India as a citizen of no other country in its history.\n",
            "\n",
            "One of the men who had come to visit and Madaraju wanted to get married but had two brothers who would not accept them.\n",
            "\n",
            "Mudra\n",
            "================================================================================\n",
            "Model prompt >>> Who is Praveen Madaraju Marquette University?\n",
            "======================================== SAMPLE 1 ========================================\n",
            " He's the son of one of the richest Indian businessmen and also the most famous businessman in India, Rajiv Raju.\" While Madaraju Marquette College is a Catholic college, its alumni include Alta Gandhi and Sir Francis Drake.\n",
            "\n",
            "According to the National Board for Education, in 2008-09 the school's graduates registered more than $100 million in annual income and $150 million of turnover. The state-held college also has 11 campuses and is home to a total of 943,000 students, the university said. Alta Gandhi's business success had raised suspicions among Indian students that even though he is a public figure, he has yet to earn any political recognition from the campus community.\n",
            "\n",
            "Read more: Indian Student Union to Invest $1.12-billion with Rs 1.6 Million in Business Venture Investing\n",
            "\n",
            "A student from the state universities told ET that his interest is in becoming a senior advisor to the Delhi administration to ensure the success of the school. While it would not be possible to reach a decision on Madaraju Marquette's future in the future, he assured the students that he would \"do whatever I can to help these people.\"\n",
            "\n",
            "Read more: Indian student union opens 'business development training'\n",
            "\n",
            "However, after the news of a potential move to the capital, many Indians who had their college and campus turned away by the government immediately started questioning what the students were getting into.\n",
            "\n",
            "\"We do not have all the answers. We don't know,\" said a man who asked to remain anonymous. \"What is the government going to do with all this money?\"\n",
            "\n",
            "The college administration, he confirmed, does not want to pay Madaraju Marquette college tuition fee in cash as it would only be used for business with student clubs or private sector companies, he added.\n",
            "\n",
            "With inputs from ET<|endoftext|>About this mod The best mod in modding! - Modules and classes, textures, scripts and other stuff that add depth to the vanilla game. Requirements DLC requirements DLC name Hearthfire Permissions and credits Author's instructions File credits This author has not credited anyone else in this file Donation Points system This mod is not opted-in to receive Donation Points\n",
            "\n",
            "Modules\n",
            "\n",
            "- A new mod with many new subclasses and classes.\n",
            "\n",
            "It's a bit more simple to learn about mods which you already know. There are two versions:-\n",
            "\n",
            "- Unofficial mod for you.\n",
            "\n",
            "- Original mod of only 1.8.\n",
            "================================================================================\n",
            "Model prompt >>> Who is John Fields Concordia University?\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "John Fields is a UF senior. After attending college for six years he left the school because he discovered he was gay and started drinking.\n",
            "\n",
            "According to Concordia's website, he is the author of a novel about friendship and the world and describes his own love for his three kids in the first issue of his bestselling novels \"Love Is Just Not For You.\"\n",
            "\n",
            "Cristiano also wrote \"Temptations Is an Exciting One,\" a memoir where his younger son was kidnapped, tortured and killed. The author spoke about his love for his children and also shared with me his love of comedy including Comedy Central's \"This Is Us,\" which he co-wrote and co-designed with Jason Schwartz. \"When I saw what a character he was he said and did everything in his power to take us on an adventure. He knew how to pull it off,\" said Scott. \"He was a great character and an incredible storyteller.\"\n",
            "\n",
            "Cristiano also helped inspire his children with the \"My Name is John\" series including \"My Daughter, My Daughter, My Daughter, Where's My Daughter?\" and \"Where's My Sister.\"\n",
            "\n",
            "\"This is a beautiful book because of the love that has surrounded us all through this time at Concordia University,\"said Scott. \"When was the last time you saw an actual book you just got out of this world?\"\n",
            "\n",
            "John Fields will also be featured in a series of interviews with UF's new members.\n",
            "\n",
            "The Concordia Graduate School of Commerce hosted the first annual graduate school discussion and was a welcoming school where anyone could be a member and receive a degree.\n",
            "\n",
            "During this second-year meeting, students were required to report the problems and troubles. There was an emphasis on diversity among the students. Other students included all the student body members who have been enrolled at the graduate school.\n",
            "\n",
            "\"In my opinion, people's hearts and their minds are at an increased level now because of how much they feel and the work they've been doing. That's all being reflected in what we're doing,\" said John Fields. \"In this first year I'm pleased and encouraged because of everything they've done over the last two years to change things for the better.\"\n",
            "\n",
            "If you have any questions, please email Concordia Faculty of Business at cfl.statestate@ufl.edu.\n",
            "\n",
            "This story has been updated with additional quotes and descriptions.\n",
            "\n",
            "Update, July 9, 2012: The university does not appear to\n",
            "================================================================================\n",
            "Model prompt >>> What is the meaning of life?\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "Is it good for people to have a family? The definition of good is love. The Bible says the following: \"For they that love are like unto a dog, and like unto a lamb, and like unto a camel, which is of one flesh, and as one flesh is of one sheep, and as one sheep is of one wife, they are not like unto a dog, but like unto a lamb, and as one sheep is of one spouse, they are not like unto a dog; but like unto a lamb is of one wife, being of one husband, being of one son.\" Likewise God is the \"God of love\" in John 14:23–24. Is life good for people? Yes! It is a good life for those living in God's presence and in God's sight, so let everyone find his or her way to one. The word \"life\" is derived from the Greek word life-, which is literally \"life\". In a good life, people will make mistakes and be better, to have the better life for themselves.\n",
            "\n",
            "Let's say you live in Jerusalem for the most part, your family is full of family and you are a member of a good family. What would the life of a good family look like? The idea is to save as much as you can so that you can live a healthy lifestyle, whether in Heaven or Hell.\n",
            "\n",
            "Let's say you are a member of a good family and you live in an apartment that has a bathroom, a shower, a kitchen, a dining room, and a conference room. How do you feel about the lifestyle, living on your own from a good family?\n",
            "\n",
            "\"For I have no choice but to live.\"\n",
            "\n",
            "We all know that God is an awesome source of love for mankind. He makes everyone happy, because there is such a deep and unique and wonderful gift to be found in Him. Therefore we are reminded of the fact that we are living in a way that doesn't have a lot more to give at once.\n",
            "\n",
            "The world needs a leader in bringing together all the people. Let me give an example to show how far we've come. I've spoken of a few people who have had their lives ruined in the past few years by the failure of the world and others. You'll see them in action as the world struggles with what can come next.\n",
            "\n",
            "It's the only way to help our society flourish and grow faster. Don't just make money working for God and helping others\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 5480, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1631, in __exit__\n",
            "    name='SessionCloseThread', target=self.close)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 796, in __init__\n",
            "    self._daemonic = current_thread().daemon\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 1116, in daemon\n",
            "    @property\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdfial0mGRvr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}